some config:
data_dir = ./data
output_dir = ./output
embedding_path = ./embedding/hlbl-embeddings-scaled.EMBEDDING_SIZE=50.txt
word_dim = 50
model_name = CNN
mode = 1
seed = 5782
cuda = 0
epoch = 20
dropout = 0.5
batch_size = 128
lr = 0.001
max_len = 100
pos_dis = 50
pos_dim = 5
hidden_size = 100
filter_num = 200
window = 3
L2_decay = 1e-05
device = cuda:0
model_dir = ./output/CNN
--------------------------------------
start to load data ...
finish!
--------------------------------------
CNN(
  (word_embedding): Embedding(246123, 50)
  (pos1_embedding): Embedding(103, 5)
  (pos2_embedding): Embedding(103, 5)
  (conv): Conv2d(1, 200, kernel_size=(3, 60), stride=(1, 1), padding=(1, 0))
  (maxpool): MaxPool2d(kernel_size=(100, 1), stride=(100, 1), padding=0, dilation=1, ceil_mode=False)
  (tanh): Tanh()
  (dropout): Dropout(p=0.5, inplace=False)
  (linear): Linear(in_features=200, out_features=100, bias=True)
  (dense): Linear(in_features=100, out_features=19, bias=True)
)
traning model parameters:
word_embedding.weight :  torch.Size([246123, 50])
pos1_embedding.weight :  torch.Size([103, 5])
pos2_embedding.weight :  torch.Size([103, 5])
conv.weight :  torch.Size([200, 1, 3, 60])
conv.bias :  torch.Size([200])
linear.weight :  torch.Size([100, 200])
linear.bias :  torch.Size([100])
dense.weight :  torch.Size([19, 100])
dense.bias :  torch.Size([19])
12,365,399 total parameters.
--------------------------------------
start to train the model ...
开始时间/s 1650605494.700448
[000] train_loss: 2.494 | dev_loss: 2.503 | micro f1 on dev: 0.4455 | pre on dev: 0.4616 | recall on dev: 0.7613 >>> save models!
[001] train_loss: 2.095 | dev_loss: 2.089 | micro f1 on dev: 0.4672 | pre on dev: 0.4551 | recall on dev: 0.6982 >>> save models!
[002] train_loss: 1.693 | dev_loss: 1.694 | micro f1 on dev: 0.4711 | pre on dev: 0.4615 | recall on dev: 0.6804 >>> save models!
[003] train_loss: 1.427 | dev_loss: 1.457 | micro f1 on dev: 0.6013 | pre on dev: 0.6117 | recall on dev: 0.6442 >>> save models!
[004] train_loss: 1.211 | dev_loss: 1.295 | micro f1 on dev: 0.6776 | pre on dev: 0.7020 | recall on dev: 0.6798 >>> save models!
[005] train_loss: 1.037 | dev_loss: 1.181 | micro f1 on dev: 0.7213 | pre on dev: 0.7267 | recall on dev: 0.7209 >>> save models!
[006] train_loss: 0.883 | dev_loss: 1.093 | micro f1 on dev: 0.7334 | pre on dev: 0.7321 | recall on dev: 0.7407 >>> save models!
[007] train_loss: 0.772 | dev_loss: 1.041 | micro f1 on dev: 0.7562 | pre on dev: 0.7746 | recall on dev: 0.7418 >>> save models!
[008] train_loss: 0.661 | dev_loss: 0.995 | micro f1 on dev: 0.7605 | pre on dev: 0.7758 | recall on dev: 0.7484 >>> save models!
[009] train_loss: 0.574 | dev_loss: 0.952 | micro f1 on dev: 0.7672 | pre on dev: 0.7730 | recall on dev: 0.7634 >>> save models!
[010] train_loss: 0.499 | dev_loss: 0.930 | micro f1 on dev: 0.7747 | pre on dev: 0.7725 | recall on dev: 0.7800 >>> save models!
[011] train_loss: 0.436 | dev_loss: 0.915 | micro f1 on dev: 0.7749 | pre on dev: 0.7746 | recall on dev: 0.7776 >>> save models!
[012] train_loss: 0.397 | dev_loss: 0.924 | micro f1 on dev: 0.7869 | pre on dev: 0.8217 | recall on dev: 0.7560 >>> save models!
[013] train_loss: 0.333 | dev_loss: 0.895 | micro f1 on dev: 0.7903 | pre on dev: 0.8030 | recall on dev: 0.7804 >>> save models!
[014] train_loss: 0.299 | dev_loss: 0.900 | micro f1 on dev: 0.7909 | pre on dev: 0.8070 | recall on dev: 0.7785 >>> save models!
[015] train_loss: 0.264 | dev_loss: 0.891 | micro f1 on dev: 0.7947 | pre on dev: 0.8115 | recall on dev: 0.7801 >>> save models!
[016] train_loss: 0.241 | dev_loss: 0.885 | micro f1 on dev: 0.7990 | pre on dev: 0.8209 | recall on dev: 0.7793 >>> save models!
[017] train_loss: 0.222 | dev_loss: 0.898 | micro f1 on dev: 0.8017 | pre on dev: 0.8282 | recall on dev: 0.7781 >>> save models!
[018] train_loss: 0.195 | dev_loss: 0.876 | micro f1 on dev: 0.8011 | pre on dev: 0.8173 | recall on dev: 0.7864 
[019] train_loss: 0.182 | dev_loss: 0.883 | micro f1 on dev: 0.8041 | pre on dev: 0.8275 | recall on dev: 0.7831 >>> save models!
--------------------------------------
start test ...
测试开始时间/s 1650605527.235853
test_loss: 0.883 | macro f1 on test:  0.8041 | p: 0.8275 | r: 0.7831
结束时间/s 1650605527.460647